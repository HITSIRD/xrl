{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.4930,   0.1683,  -0.0398,  ...,   0.1388,  -0.2933,   1.4138],\n",
      "        [ -0.3318,   0.5863,   0.9878,  ...,  -0.0278,   1.0599,   0.4682],\n",
      "        [  0.3920,   1.8801,   1.3467,  ...,   1.2708,   0.0658,   0.0992],\n",
      "        ...,\n",
      "        [-15.0019, -13.9263,  -0.5682,  ..., -13.7954,  -4.4415, -16.2678],\n",
      "        [  0.4264,   0.7387, -16.2612,  ..., -12.0022,  -0.7318,   1.7525],\n",
      "        [-13.7561,   0.2019,   0.8381,  ...,   0.5595,   1.0081, -17.2911]])\n",
      "tensor([[-1.6636e-01,  4.4661e+00,  1.0705e+00,  ...,  5.1678e-02,\n",
      "         -1.0906e-01,  2.3444e-01],\n",
      "        [ 7.6785e-01, -2.4005e+00, -2.0293e+00,  ..., -6.2359e-02,\n",
      "          2.2932e-02, -9.6292e-01],\n",
      "        [-1.2131e-01, -2.2562e-01,  4.9384e-01,  ..., -5.1090e-02,\n",
      "         -4.4676e-02,  2.3678e-01],\n",
      "        ...,\n",
      "        [-1.7346e+00, -3.5562e+00, -2.3660e+00,  ..., -2.9540e-02,\n",
      "         -3.3692e-03,  1.8367e+00],\n",
      "        [ 7.0553e-01, -5.9258e+00,  9.9596e-01,  ...,  5.2658e-02,\n",
      "          2.7574e-02, -7.7244e-01],\n",
      "        [ 1.6368e+00,  8.1030e+00,  1.0821e+00,  ..., -2.6978e-02,\n",
      "          2.7041e-02, -1.7020e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 加载 .pth 文件\n",
    "file_path = './weight/mkbl_weights_ep24.pth' \n",
    "checkpoint = torch.load(file_path, map_location='cpu')\n",
    "\n",
    "# for k, v in checkpoint['state_dict']['ll_agent'].items():\n",
    "#     print(k)\n",
    "#     # print(v)\n",
    "\n",
    "print(checkpoint['state_dict']['hl_agent']['policy.net.p.0.dc_leaves'])\n",
    "print(checkpoint['state_dict']['hl_agent']['policy.net.p.0.dc_inner_nodes.weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQCDTPredictor(nn.Module):\n",
    "    def __init__(self, hp, input_dim, output_dim):\n",
    "        super(VQCDTPredictor, self).__init__()\n",
    "\n",
    "        # 设置属性\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        if hp.feature_learning_depth >= 0:\n",
    "            self.num_intermediate_variables = hp.num_intermediate_variables\n",
    "        else:\n",
    "            self.num_intermediate_variables = input_dim\n",
    "        self.feature_learning_depth = hp.feature_learning_depth\n",
    "        self.decision_depth = hp.decision_depth\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.greatest_path_probability = hp.greatest_path_probability\n",
    "\n",
    "        self.beta_fl = hp.beta_fl\n",
    "        self.beta_dc = hp.beta_dc\n",
    "\n",
    "        self.device = hp.device\n",
    "\n",
    "        # 初始化特征学习和决策模块\n",
    "        self.feature_learning_init()\n",
    "        self.decision_init()\n",
    "\n",
    "        if self.greatest_path_probability:\n",
    "            print('use best path')\n",
    "\n",
    "        # 最大叶节点索引\n",
    "        self.max_leaf_idx = None\n",
    "\n",
    "        self.if_smooth = hp.if_smooth\n",
    "\n",
    "        self.tree_name = hp.tree_name\n",
    "        self.if_save = hp.if_save\n",
    "        self.forward_num = 0 # 用来保存模型\n",
    "        # self.model_name = os.path.join(os.environ[\"EXP_DIR\"], f\"cdt_model/{self.tree_name}.pth\")\n",
    "\n",
    "        self.if_discrete = getattr(hp, 'if_discrete', False)\n",
    "\n",
    "    def feature_learning_init(self):\n",
    "        if self.feature_learning_depth < 0:  # 特征树深度小于0时不需要特征树\n",
    "            print('use SDT')\n",
    "            return\n",
    "        else:\n",
    "            print('use CDT')\n",
    "            self.num_fl_inner_nodes = 2 ** self.feature_learning_depth - 1\n",
    "            self.num_fl_leaves = self.num_fl_inner_nodes + 1\n",
    "            self.fl_inner_nodes = nn.Linear(self.input_dim + 1, self.num_fl_inner_nodes, bias=False)\n",
    "            # coefficients of feature combinations\n",
    "            fl_leaf_weights = torch.randn(self.num_fl_leaves * self.num_intermediate_variables, self.input_dim)\n",
    "            self.fl_leaf_weights = nn.Parameter(fl_leaf_weights)\n",
    "\n",
    "            # temperature term\n",
    "            if self.beta_fl is True or self.beta_fl == 1:  # learnable\n",
    "                beta_fl = torch.randn(self.num_fl_inner_nodes)  # use different beta_fl for each node\n",
    "                # beta_fl = torch.randn(1)     # or use one beta_fl across all nodes\n",
    "                self.beta_fl = nn.Parameter(beta_fl)\n",
    "            elif self.beta_fl is False or self.beta_fl == 0:\n",
    "                self.beta_fl = torch.ones(1).to(self.device)  # or use one beta_fl across all nodes\n",
    "            else:  # pass in value for beta_fl\n",
    "                self.beta_fl = torch.tensor(self.beta_fl).to(self.device)\n",
    "\n",
    "    def feature_learning_forward(self):\n",
    "        \"\"\" \n",
    "        Forward the tree for feature learning.\n",
    "        Return the probabilities for reaching each leaf.\n",
    "        \"\"\"\n",
    "        if self.feature_learning_depth < 0:\n",
    "            return None\n",
    "        else:\n",
    "            path_prob = self.sigmoid(self.beta_fl * self.fl_inner_nodes(self.aug_data))\n",
    "\n",
    "            path_prob = torch.unsqueeze(path_prob, dim=2)\n",
    "            path_prob = torch.cat((path_prob, 1 - path_prob), dim=2)\n",
    "            _mu = self.aug_data.data.new(self.batch_size, 1, 1).fill_(1.)\n",
    "\n",
    "            begin_idx = 0\n",
    "            end_idx = 1\n",
    "            for layer_idx in range(0, self.feature_learning_depth):\n",
    "                _path_prob = path_prob[:, begin_idx:end_idx, :]\n",
    "\n",
    "                _mu = _mu.view(self.batch_size, -1, 1).repeat(1, 1, 2)\n",
    "                _mu = _mu * _path_prob\n",
    "                begin_idx = end_idx  # index for each layer\n",
    "                end_idx = begin_idx + 2 ** (layer_idx + 1)\n",
    "            mu = _mu.view(self.batch_size, self.num_fl_leaves)\n",
    "\n",
    "            return mu\n",
    "\n",
    "    def decision_init(self):\n",
    "        self.num_dc_inner_nodes = 2 ** self.decision_depth - 1\n",
    "        self.num_dc_leaves = self.num_dc_inner_nodes + 1\n",
    "        self.dc_inner_nodes = nn.Linear(self.num_intermediate_variables + 1, self.num_dc_inner_nodes, bias=False)\n",
    "\n",
    "        dc_leaves = torch.randn(self.num_dc_leaves, self.output_dim)\n",
    "        self.dc_leaves = nn.Parameter(dc_leaves)  # 可训练的二维张量\n",
    "\n",
    "        # temperature term\n",
    "        if self.beta_dc is True or self.beta_dc == 1:  # learnable\n",
    "            beta_dc = torch.randn(self.num_dc_inner_nodes)  # use different beta_dc for each node\n",
    "            # beta_dc = torch.randn(1)     # or use one beta_dc across all nodes\n",
    "            self.beta_dc = nn.Parameter(beta_dc)\n",
    "        elif self.beta_dc is False or self.beta_dc == 0:\n",
    "            self.beta_dc = torch.ones(1).to(self.device)  # or use one beta_dc across all nodes\n",
    "        else:  # pass in value for beta_dc\n",
    "            self.beta_dc = torch.tensor(self.beta_dc).to(self.device)\n",
    "\n",
    "    def decision_forward(self):\n",
    "        \"\"\"\n",
    "        Forward the differentiable decision tree\n",
    "        \"\"\"\n",
    "        if self.feature_learning_depth >= 0:\n",
    "            self.intermediate_features_construct()  # 计算中间特征self.features: (batch_size*num_fl_leaves, num_intermediate_variables)\n",
    "        else:\n",
    "            self.features = self.data  # (batch_size, input_dim)\n",
    "\n",
    "        aug_features = self._data_augment_(self.features)\n",
    "        path_prob = self.sigmoid(self.beta_dc * self.dc_inner_nodes(aug_features))\n",
    "        feature_batch_size = self.features.shape[0]\n",
    "\n",
    "        path_prob = torch.unsqueeze(path_prob, dim=2)\n",
    "        path_prob = torch.cat((path_prob, 1 - path_prob), dim=2)\n",
    "        _mu = aug_features.data.new(feature_batch_size, 1, 1).fill_(1.)\n",
    "\n",
    "        begin_idx = 0\n",
    "        end_idx = 1\n",
    "        for layer_idx in range(0, self.decision_depth):\n",
    "            _path_prob = path_prob[:, begin_idx:end_idx, :]\n",
    "\n",
    "            _mu = _mu.view(feature_batch_size, -1, 1).repeat(1, 1, 2)\n",
    "            _mu = _mu * _path_prob\n",
    "            begin_idx = end_idx  # index for each layer\n",
    "            end_idx = begin_idx + 2 ** (layer_idx + 1)\n",
    "        mu = _mu.view(feature_batch_size, self.num_dc_leaves)  # (batch_size*num_fl_leaves, num_dc_leaves)\n",
    "\n",
    "        return mu\n",
    "\n",
    "    def discrete_decision_forward(self):\n",
    "        if self.feature_learning_depth >= 0:\n",
    "            self.intermediate_features_construct()  # 计算中间特征self.features: (batch_size*num_fl_leaves, num_intermediate_variables)\n",
    "        else:\n",
    "            self.features = self.data  # (batch_size, input_dim)\n",
    "\n",
    "        aug_features = self._data_augment_(self.features)\n",
    "        path_prob = self.sigmoid(self.beta_dc * self.dc_inner_nodes(aug_features))\n",
    "        feature_batch_size = self.features.shape[0]\n",
    "\n",
    "        path_prob = torch.unsqueeze(path_prob, dim=2)\n",
    "        path_prob = torch.cat((path_prob, 1 - path_prob), dim=2)\n",
    "        path_prob = torch.where(path_prob > 0.5, torch.tensor(1.0, device=self.device), torch.tensor(0.0, device=self.device)) # 大于0.5设置为1\n",
    "        _mu = aug_features.data.new(feature_batch_size, 1, 1).fill_(1.)\n",
    "\n",
    "        begin_idx = 0\n",
    "        end_idx = 1\n",
    "        for layer_idx in range(0, self.decision_depth):\n",
    "            _path_prob = path_prob[:, begin_idx:end_idx, :]\n",
    "\n",
    "            _mu = _mu.view(feature_batch_size, -1, 1).repeat(1, 1, 2)\n",
    "            _mu = _mu * _path_prob\n",
    "            begin_idx = end_idx  # index for each layer\n",
    "            end_idx = begin_idx + 2 ** (layer_idx + 1)\n",
    "        mu = _mu.view(feature_batch_size, self.num_dc_leaves)  # (batch_size*num_fl_leaves, num_dc_leaves)\n",
    "\n",
    "        return mu\n",
    "\n",
    "    def intermediate_features_construct(self):\n",
    "        \"\"\"\n",
    "        Construct the intermediate features for decision making, with learned feature combinations from feature learning module.\n",
    "        \"\"\"\n",
    "        features = self.fl_leaf_weights.view(-1, self.input_dim) @ self.data.transpose(0,\n",
    "                                                                                       1)  # data: (batch_size, feature_dim); return: (num_fl_leaves*num_intermediate_variables, batch)\n",
    "        self.features = features.contiguous().view(self.num_fl_leaves, self.num_intermediate_variables, -1).permute(2,\n",
    "                                                                                                                    0,\n",
    "                                                                                                                    1).contiguous().view(\n",
    "            -1,\n",
    "            self.num_intermediate_variables)  # return: (N, num_intermediate_variables) where N=batch_size*num_fl_leaves\n",
    "\n",
    "    def decision_leaves(self, p):  # p：到达每个叶节点的概率\n",
    "        if self.if_smooth:\n",
    "            distribution_per_leaf = self.softmax(self.dc_leaves / (self.output_dim)**0.5)\n",
    "        else:\n",
    "            distribution_per_leaf = self.softmax(self.dc_leaves)   # distribution_per_leaf：不同动作叶子输出不同动作的概率\n",
    "        average_distribution = torch.mm(p, distribution_per_leaf)  # sum(probability of each leaf * leaf distribution)\n",
    "        return average_distribution  # (batch_size, output_dim) # 各动作的概率\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.if_save:\n",
    "            self.forward_num = self.forward_num + 1\n",
    "            if self.forward_num >= 100000:\n",
    "                self.forward_num = 0\n",
    "                self.save_model(self.model_name)\n",
    "        LogProb = False\n",
    "        self.data = data\n",
    "        self.batch_size = data.size()[0]\n",
    "\n",
    "        if self.feature_learning_depth >= 0:\n",
    "            self.aug_data = self._data_augment_(data)\n",
    "            fl_probs = self.feature_learning_forward()  # (batch_size, num_fl_leaves), 在该特征下到达不同中间特征叶子的概率\n",
    "            if self.if_discrete:\n",
    "                dc_probs = self.discrete_decision_forward()  # (batch_size*num_fl_leaves, num_dc_leaves)\n",
    "            else:\n",
    "                dc_probs = self.decision_forward()\n",
    "            dc_probs = dc_probs.view(self.batch_size, self.num_fl_leaves,\n",
    "                                     -1)  # (batch_size, num_fl_leaves, num_dc_leaves), 在不同中间特征叶子的特征下到达不同动作叶子的概率\n",
    "\n",
    "            _mu = torch.bmm(fl_probs.unsqueeze(1), dc_probs).squeeze(1)  # (batch_size, num_dc_leaves), 在该特征下到达不同动作叶子的概率\n",
    "            output = self.decision_leaves(_mu)\n",
    "\n",
    "            if self.greatest_path_probability:\n",
    "                vs, ids = torch.max(fl_probs,\n",
    "                                    1)  # ids is the leaf index with maximal path probability: 在特征下最有可能的中间特征叶子的索引\n",
    "                # get the path with greatest probability, get index of it, feature vector and feature value on that leaf\n",
    "                self.max_leaf_idx_fl = ids\n",
    "                self.max_feature_vector = \\\n",
    "                self.fl_leaf_weights.view(self.num_fl_leaves, self.num_intermediate_variables, self.input_dim)[ids]\n",
    "                self.max_feature_value = self.features.view(-1, self.num_fl_leaves, self.num_intermediate_variables)[:,\n",
    "                                         ids, :]\n",
    "\n",
    "                one_dc_probs = dc_probs[torch.arange(dc_probs.shape[0]), ids,\n",
    "                               :]  # select decision path probabilities of learned features with largest probability\n",
    "                one_hot_path_probability_dc = torch.zeros(one_dc_probs.shape).to(self.device)\n",
    "                vs_dc, ids_dc = torch.max(one_dc_probs,\n",
    "                                          1)  # ids is the leaf index with maximal path probability: 在中间特征下最有可能的动作叶子的索引\n",
    "                self.max_leaf_idx_dc = ids_dc\n",
    "                one_hot_path_probability_dc.scatter_(1, ids_dc.view(-1, 1), 1.)\n",
    "                prediction = self.decision_leaves(one_hot_path_probability_dc)\n",
    "\n",
    "            else:  # prediction value equals to the average distribution\n",
    "                prediction = output\n",
    "\n",
    "            if LogProb:\n",
    "                output = torch.log(output)  # 根据所有叶节点得到的输出\n",
    "                prediction = torch.log(prediction)  # 根据最优路径得到的输出\n",
    "\n",
    "        else:\n",
    "            if self.if_discrete:\n",
    "                dc_probs = self.discrete_decision_forward()  # (batch_size, num_dc_leaves)\n",
    "            else:\n",
    "                dc_probs = self.decision_forward()\n",
    "            _mu = dc_probs\n",
    "            output = self.decision_leaves(_mu)\n",
    "\n",
    "            if self.greatest_path_probability:\n",
    "                one_dc_probs = dc_probs\n",
    "                one_hot_path_probability_dc = torch.zeros(one_dc_probs.shape).to(self.device)\n",
    "                vs_dc, ids_dc = torch.max(one_dc_probs, 1)\n",
    "                self.max_leaf_idx_dc = ids_dc\n",
    "                one_hot_path_probability_dc.scatter_(1, ids_dc.view(-1, 1), 1.)\n",
    "                prediction = self.decision_leaves(one_hot_path_probability_dc)\n",
    "\n",
    "            else:  # prediction value equals to the average distribution\n",
    "                prediction = output\n",
    "\n",
    "            if LogProb:\n",
    "                output = torch.log(output)  # 根据所有叶节点得到的输出\n",
    "                prediction = torch.log(prediction)  # 根据最优路径得到的输出\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def _data_augment_(self, input):    # 在前边加上偏置项\n",
    "        batch_size = input.size()[0]\n",
    "        input = input.view(batch_size, -1)\n",
    "        bias = torch.ones(batch_size, 1).to(self.device)\n",
    "        input = torch.cat((bias, input), 1)\n",
    "        return input\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        self.eval()\n",
    "\n",
    "    def load_checkpoint(self, file_path):\n",
    "        # 加载检查点文件\n",
    "        checkpoint = torch.load(file_path, map_location='cpu')\n",
    "        self.dc_leaves.data = checkpoint['state_dict']['hl_agent']['policy.net.p.0.dc_leaves']\n",
    "        self.dc_inner_nodes.weight.data = checkpoint['state_dict']['hl_agent']['policy.net.p.0.dc_inner_nodes.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use SDT\n"
     ]
    }
   ],
   "source": [
    "# 绘制代码\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib as mpl\n",
    "# from spirl.configs import local\n",
    "\n",
    "\n",
    "\n",
    "def get_binary_index(tree):\n",
    "    \"\"\"\n",
    "    Get binary index for tree nodes:\n",
    "    From\n",
    "\n",
    "    0\n",
    "    1 2\n",
    "    3 4 5 6 \n",
    "\n",
    "    to \n",
    "\n",
    "    '0'\n",
    "    '00' '01' \n",
    "    '000' '001' '010' '011'\n",
    "\n",
    "    \"\"\"\n",
    "    index_list = []\n",
    "    for layer_idx in range(0, tree.max_depth+1):\n",
    "        index_list.append([bin(i)[2:].zfill(layer_idx+1) for i in range(0, np.power(2, layer_idx))])\n",
    "    return np.concatenate(index_list)\n",
    "\n",
    "def path_from_prediction(tree, idx):\n",
    "    \"\"\"\n",
    "    Generate list of nodes as decision path, \n",
    "    with each node represented by a binary string and an int index\n",
    "    \"\"\"\n",
    "    binary_idx_list = []\n",
    "    int_idx_list=[]\n",
    "    idx = int(idx)\n",
    "    for layer_idx in range(tree.max_depth+1, 0, -1):\n",
    "        binary_idx_list.append(bin(idx)[2:].zfill(layer_idx))\n",
    "        int_idx_list.append(2**(layer_idx-1)-1+idx)\n",
    "        idx = int(idx/2)\n",
    "    binary_idx_list.reverse()  # from top to bottom\n",
    "    int_idx_list.reverse() \n",
    "    return binary_idx_list, int_idx_list\n",
    "\n",
    "def draw_tree(original_tree, input_img=None, show_correlation=False, DrawTree=None, savepath=''):\n",
    "    '''\n",
    "    Need to carefully select several configurations for well displaying trees for different environments, e.g. CartPole and LunarLander-v2\n",
    "    '''\n",
    "    # 整体\n",
    "    aspect_inners = 0.6\n",
    "    aspect_leaves = 0.6\n",
    "    arrow_color = '#262626'\n",
    "\n",
    "    # # 局部\n",
    "    # aspect_inners = 1\n",
    "    # aspect_leaves = 1\n",
    "    # arrow_color = '#262626'\n",
    "\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "    tree = copy.copy(original_tree)\n",
    "    if DrawTree=='FL': # draw the feature learning tree\n",
    "        tree.inner_node_num = tree.num_fl_inner_nodes\n",
    "        tree.max_depth = tree.feature_learning_depth\n",
    "        tree.leaf_num = tree.num_fl_leaves\n",
    "        inner_nodes_name='fl_inner_nodes.weight'\n",
    "        leaf_nodes_name='fl_leaf_weights'\n",
    "        input_shape=(tree.input_dim,)\n",
    "\n",
    "    elif DrawTree == 'DM':  # draw the decision making tree\n",
    "        tree.inner_node_num = tree.num_dc_inner_nodes\n",
    "        tree.max_depth = tree.decision_depth\n",
    "        tree.leaf_num = tree.num_dc_leaves\n",
    "        inner_nodes_name='dc_inner_nodes.weight'\n",
    "        leaf_nodes_name='dc_leaves'\n",
    "        input_shape=(tree.num_intermediate_variables,)\n",
    "        # input_img=tree.max_feature_value.squeeze().detach().cpu().numpy()  # replace the original input image to be intermediate feature value\n",
    "\n",
    "    def _add_arrow(ax_parent, ax_child, xyA, xyB, color='black', linestyle=None):\n",
    "        '''Private utility function for drawing arrows between two axes.'''\n",
    "        con = ConnectionPatch(xyA=xyA, xyB=xyB, coordsA='data', coordsB='data',\n",
    "                              axesA=ax_child, axesB=ax_parent, arrowstyle='<-,head_length=0.8,head_width=0.4',\n",
    "                              color=color, linewidth=tree.max_depth-2, linestyle=linestyle)\n",
    "        ax_child.add_artist(con)\n",
    "\n",
    "    inner_nodes = tree.state_dict()[inner_nodes_name]\n",
    "    leaf_nodes = tree.state_dict()[leaf_nodes_name]\n",
    "    binary_indices = get_binary_index(tree)\n",
    "    inner_indices = binary_indices[:tree.inner_node_num]\n",
    "    leaf_indices = binary_indices[tree.inner_node_num:]\n",
    "    \n",
    "    if len(input_shape) == 3:\n",
    "        img_rows, img_cols, img_chans = input_shape\n",
    "    elif len(input_shape) == 1:\n",
    "        img_rows, img_cols = input_shape[0], input_shape[0]\n",
    "\n",
    "    if DrawTree == 'FL':  # each leaf contains vectors of number: tree.args['num_intermediate_variables'] \n",
    "        leaf_nodes = leaf_nodes.view(tree.leaf_num, tree.num_intermediate_variables, tree.input_dim)\n",
    "\n",
    "    kernels = dict([(node_idx, node_value.cpu().numpy().reshape(input_shape)) for node_idx, node_value in zip (inner_indices, inner_nodes[:, 1:]) ])\n",
    "    biases = dict([(node_idx, node_value.cpu().numpy().squeeze()) for node_idx, node_value in zip (inner_indices, inner_nodes[:, :1]) ])\n",
    "    leaves = dict([(leaf_idx, np.array([leaf_dist.cpu().numpy()])) for leaf_idx, leaf_dist in zip (leaf_indices, leaf_nodes) ])\n",
    "    n_leaves = tree.leaf_num\n",
    "    assert len(leaves) == n_leaves\n",
    "\n",
    "    fig = plt.figure(figsize=(2*n_leaves, n_leaves/2), facecolor='white')  # for cartpole\n",
    "    gs = GridSpec(tree.max_depth+1, n_leaves*2, height_ratios=[1]*tree.max_depth+[0.5]) # 高度调整\n",
    "\n",
    "    # Grid Coordinate X (horizontal)\n",
    "    gcx = [list(np.arange(1, 2**(i+1), 2) * (2**(tree.max_depth+1) // 2**(i+1)))\n",
    "           for i in range(tree.max_depth+1)]\n",
    "    gcx = list(itertools.chain.from_iterable(gcx))\n",
    "    axes = {}\n",
    "    path = ['0']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    # 权重颜色\n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    new_cmap = cmap(np.linspace(0.08, 0.92, 256))  # 调整对比度，避免最强的红色和蓝色\n",
    "    # 创建新的颜色映射\n",
    "    new_cmap = mcolors.LinearSegmentedColormap.from_list('less_intense_coolwarm', new_cmap)\n",
    "\n",
    "    imshow_args = {'origin': 'upper', 'interpolation': 'None', 'cmap': plt.get_cmap(new_cmap)}\n",
    "    imshow_args = {'origin': 'upper', 'interpolation': 'None', 'cmap': 'Oranges'} # OrRd、Reds、YlOrBr\n",
    "\n",
    "    # 权重参数\n",
    "    kernel_min_val = np.min([np.min(kernel) for kernel in kernels.values()])\n",
    "    kernel_max_val = np.max([np.max(kernel) for kernel in kernels.values()])\n",
    "    leaf_min_val = np.min([np.min(leaf) for leaf in leaves.values()])\n",
    "    leaf_max_val = np.max([np.max(leaf) for leaf in leaves.values()])\n",
    "\n",
    "    # mkbl、mlsh参数\n",
    "    kernel_min_val = 0.0\n",
    "    kernel_max_val = 7.\n",
    "    leaf_min_val = 0.0 # 小红多\n",
    "    leaf_max_val = 0.4 # 大蓝多\n",
    "\n",
    "    # # calvin参数\n",
    "    # kernel_min_val = 0.0\n",
    "    # kernel_max_val = 18.\n",
    "    # leaf_min_val = 0.0 # 小红多\n",
    "    # leaf_max_val = 0.8 # 大蓝多\n",
    "\n",
    "    # plot color bar for kernels and leaves separately\n",
    "    norm = mpl.colors.Normalize(vmin=kernel_min_val,vmax=kernel_max_val)\n",
    "    sm = plt.cm.ScalarMappable(cmap=imshow_args['cmap'], norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbaxes = fig.add_axes([0.01, 0.4, 0.03, 0.2])  # This is the position for the colorbar\n",
    "    plt.colorbar(sm, ticks=np.linspace(kernel_min_val,kernel_max_val,5), cax = cbaxes)\n",
    "        \n",
    "    # draw tree nodes\n",
    "    for pos, key in enumerate(sorted(kernels.keys(), key=lambda x:(len(x), x))):\n",
    "        ax = plt.subplot(gs[len(key)-1, gcx[pos]-2:gcx[pos]+2])\n",
    "        axes[key] = ax\n",
    "        kernel_image = kernels[key]\n",
    "\n",
    "        if len(kernel_image.shape)==3: # 2D image (H, W, C)\n",
    "            ax.imshow(kernel_image.squeeze(), vmin=kernel_min_val, vmax=kernel_max_val, **imshow_args)\n",
    "        elif len(kernel_image.shape)==1:\n",
    "            vector_image = np.ones((kernel_image.shape[0], 1)) @ [kernel_image]\n",
    "            ax.imshow(vector_image, vmin=kernel_min_val, vmax=kernel_max_val, **imshow_args)\n",
    "        # 保留坐标轴，但去除刻度线和标签\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        # ax.axis('off')\n",
    "\n",
    "        ax.set_aspect(aspect=aspect_inners) # imp：节点宽高比\n",
    "\n",
    "        # # 绘制子任务序号\n",
    "        # if DrawTree!='FL':  # feature learning tree do not have titile indicating the classification \n",
    "        #     digits = set([np.argmax(leaves[k]) for k in leaves.keys()\n",
    "        #                 if k.startswith(key)])\n",
    "        #     title = ','.join(str(digit) for digit in digits)\n",
    "        #     plt.title('{}'.format(title))\n",
    "\n",
    "    imshow_args = {'origin': 'upper', 'interpolation': 'None', 'cmap': 'Greens'} # YlGn\n",
    "\n",
    "    # draw tree leaves\n",
    "    for pos, key in enumerate(sorted(leaves.keys(), key=lambda x:(len(x), x))):\n",
    "        ax = plt.subplot(gs[len(key)-1,\n",
    "                            gcx[len(kernels)+pos]-1:gcx[len(kernels)+pos]+1])\n",
    "        axes[key] = ax\n",
    "        if len(leaves[key].shape)>2:  # output multi-dimension, e.g. intermediate features for feature learning tree\n",
    "            leaf_image = leaves[key].squeeze(0)\n",
    "        else:\n",
    "            leaf_image = np.ones((tree.output_dim, 1)) @ leaves[key]\n",
    "\n",
    "        def softmax_for_rows(matrix):\n",
    "            # 对每一行的元素应用 exp 函数，同时减去该行的最大值以避免数值溢出\n",
    "            exps = np.exp(matrix - np.amax(matrix, axis=1, keepdims=True))\n",
    "            # 计算每一行的指数之和\n",
    "            sum_exps = np.sum(exps, axis=1, keepdims=True)\n",
    "            # 进行归一化，使每一行的和为 1\n",
    "            probabilities = exps / sum_exps\n",
    "            return probabilities\n",
    "        \n",
    "        leaf_image = softmax_for_rows(leaf_image)\n",
    "\n",
    "        ax.imshow(leaf_image, vmin=leaf_min_val, vmax=leaf_max_val, **imshow_args)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax.set_aspect(aspect=aspect_leaves) # imp：节点宽高比\n",
    "\n",
    "        # 绘制子任务序号\n",
    "        if DrawTree!='FL':  # feature learning tree do not have titile indicating the classification \n",
    "            plt.title('{}'.format(np.argmax(leaves[key])), y=-.5)\n",
    "        \n",
    "    # add arrows indicating flow\n",
    "    for pos, key in enumerate(sorted(axes.keys(), key=lambda x:(len(x), x))):\n",
    "        children_keys = [k for k in axes.keys()\n",
    "                         if len(k) == len(key) + 1 and k.startswith(key)]\n",
    "        for child_key in children_keys:\n",
    "            p_rows, p_cols = axes[key].get_images()[0].get_array().shape\n",
    "            c_rows, c_cols = axes[child_key].get_images()[0].get_array().shape\n",
    "\n",
    "            # 调整箭头的起点和终点位置\n",
    "            parent_position = (p_cols // 2, p_rows - 1)  # 上移1个单位\n",
    "            child_position = (c_cols // 2, 1 - 1)  # 上移1个单位\n",
    "\n",
    "            linestyle = None\n",
    "            _add_arrow(axes[key], axes[child_key], child_position, parent_position, color=arrow_color, linestyle=linestyle)\n",
    "\n",
    "\n",
    "    # draw input image with arrow indicating flow into the root node\n",
    "    if input_img is not None:\n",
    "        ax = plt.subplot(gs[0, 0:4])  # for lunarlander\n",
    "        img_min_val = np.min(input_img)\n",
    "        img_max_val = np.max(input_img)\n",
    "        if len(input_img.shape)==3: # 2D image (H, W, C)\n",
    "            ax.imshow(input_img.squeeze(), clim=(0.0, 1.0), vmin=img_min_val, vmax=img_max_val, **imshow_args)\n",
    "        elif len(input_img.shape)==1:\n",
    "            vector_image = np.ones((input_img.shape[0], 1)) @ [input_img]\n",
    "            ax.imshow(vector_image, vmin=img_min_val, vmax=img_max_val, **imshow_args)\n",
    "        ax.axis('off')\n",
    "        plt.title('input')\n",
    "        norm = mpl.colors.Normalize(vmin=img_min_val,vmax=img_max_val)\n",
    "        sm = plt.cm.ScalarMappable(cmap=imshow_args['cmap'], norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbaxes = fig.add_axes([0.01, 0.7, 0.03, 0.2])  # This is the position for the colorbar\n",
    "        plt.colorbar(sm, ticks=np.linspace(img_min_val,img_max_val,5), cax = cbaxes)\n",
    "\n",
    "\n",
    "\n",
    "    norm = mpl.colors.Normalize(vmin=leaf_min_val,vmax=leaf_max_val)\n",
    "    sm = plt.cm.ScalarMappable(cmap=imshow_args['cmap'], norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbaxes = fig.add_axes([0.01, 0.1, 0.03, 0.2])  # This is the position for the colorbar, second dim is y, from bottom to top in img: 0->1\n",
    "    plt.colorbar(sm, ticks=np.linspace(leaf_min_val,leaf_max_val,5), cax = cbaxes)\n",
    "\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, facecolor=fig.get_facecolor())\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def get_path(tree, input, Probs=False):\n",
    "    tree.forward(torch.Tensor(input).unsqueeze(0))\n",
    "    max_leaf_idx = tree.max_leaf_idx\n",
    "    _, path_idx_int = path_from_prediction(tree, max_leaf_idx)\n",
    "    if Probs:\n",
    "        return path_idx_int, tree.inner_probs.squeeze().detach().cpu().numpy()\n",
    "    else:\n",
    "        return path_idx_int\n",
    "\n",
    "import torch\n",
    "\n",
    "# 模型配置\n",
    "codebook = 16\n",
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.codebook_K = codebook\n",
    "        self.feature_learning_depth = -1\n",
    "        self.decision_depth = 6\n",
    "        self.num_intermediate_variables = 20\n",
    "        self.greatest_path_probability = False\n",
    "        self.beta_fl = False\n",
    "        self.beta_dc = False\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.if_smooth = False\n",
    "        self.tree_name = ''\n",
    "        self.if_save = False\n",
    "hp = HyperParameters()\n",
    "\n",
    "tree = VQCDTPredictor(hp, 60, codebook)\n",
    "# tree.load_model('/home/zuo/project/xrl/spirl/experiments/old_results1/cdt_model/16_-1+60+6+0_s6_2copy.pth')\n",
    "tree.load_checkpoint('./weight/mlsh_weights_ep24.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc_leaves 1024\n",
      "dc_inner_nodes.weight 3843\n",
      "Total number of parameters in model:  4867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 参数打印\n",
    "num_params = 0\n",
    "for key, v in tree.state_dict().items():\n",
    "    print(key, v.reshape(-1).shape[0])\n",
    "    num_params+=v.reshape(-1).shape[0]\n",
    "print('Total number of parameters in model: ', num_params)\n",
    "\n",
    "draw_tree(tree, input_img=None, DrawTree='DM', savepath='./临时/mlsh_tree.pdf')\n",
    "# draw_tree_with_params(tree, savepath='/home/zuo/project/xrl/spirl/experiments/cdt_model/16+0+5+20+test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
